seed: 42

# Only for 0,1 image pair
log:
  # group_name: 'my_subset'
  # group_name: 'scene0_all'
  group_name: 'all'
  run_name: 'FixDual_my_${finetune.args.consist_loss_ratio}:${finetune.args.pred_loss_ratio}_step${finetune.args.ddpm_steps}'
  run_path: dt9j4xvd

data:
  name: GSO # OO3D
  root_dir: rendering

  scene: 3D_Dollhouse_Happy_Brother
  id: 0,1

  # train
  image_dir: ${data.root_dir}/${data.name}/${data.scene}/train/rgb
  gt_transform_fp: ${data.root_dir}/${data.name}/${data.scene}/train/transform.json

  # test
  test_image_dir: ${data.root_dir}/${data.name}/${data.scene}/test/rgb
  test_transform_fp: ${data.root_dir}/${data.name}/${data.scene}/test/transform.json

  # pose exp
  exp_root: exp
  exp_dir: ${data.exp_root}/${data.name}/${data.scene}/${data.id}
  transform_fp: ${data.exp_dir}/transform.json
  scene_transform_fp: null

  # nvs exp
  nvs_root: ${data.exp_root}
  nvs_dir: ${data.nvs_root}/${data.name}/${data.scene}
  lora_ckpt_fp: ${data.nvs_dir}/lora.ckpt
  demo_fp:  ${data.nvs_dir}/demo.png

model:
  name: zero123adv
  args:
    pretrained_model_name_or_path: ldm/ckpt/zero123-xl.ckpt
    pretrained_config: ldm/ckpt/sd-objaverse-finetune-c_concat-256.yaml
    vram_O: false

pose:
  # image_dir: ${data.image_dir}
  # transform_fp: ${data.transform_fp}
  # scene_transform_fp: ${data.scene_transform_fp}
  # demo_fp: ${data.demo_fp}
  # id: ${data.id}
  # init_latlon: [[0, 0, 1], [0, 90, 1], [0, 180, 1], [0, -90, 1]]
  # default_theta: 0
  # default_azimuth: 0
  # default_radius: 1.0
  # default_latlon: ['${pose.default_theta}', '${pose.default_azimuth}', '${pose.default_radius}']
  # search_radius_range: 0.8
  # use_step_ratio: true
  # use_dualway: true

  # args:
  #   max_step: 100
  #   optimizer:
  #     name: Adam
  #     args:
  #       lr: 1.0e-1
  #       betas: [0.9, 0.999]
  #   scheduler:
  #     name: ReduceLROnPlateau
  #     args:
  #       mode: min
  #       factor: 0.6
  #       patience: 10

finetune:
  image_dir: ${data.image_dir}
  transform_fp: ${data.transform_fp}
  lora_ckpt_fp: ${data.lora_ckpt_fp}
  lora_rank: 12
  lora_target_replace_module: [CrossAttention, GEGLU]

  args:
    max_step: 100
    batch_size: 8
    consist_loss_ratio: 2
    pred_loss_ratio: 1
    ddpm_steps: 999
    optimizer:
      name: Adam
      args:
        lr: 1.0e-3
        betas: [0.9, 0.999]
    scheduler:
      name: MultiStepLR
      args:
        milestones: [25]
        gamma: 0.1

inference:
  image_dir: ${data.image_dir}
  transform_fp: ${data.transform_fp}
  test_transform_fp: ${data.test_transform_fp}
  lora_ckpt_fp: ${data.lora_ckpt_fp}
  demo_fp: ${data.demo_fp}
  lora_rank: ${finetune.lora_rank}
  lora_target_replace_module: ${finetune.lora_target_replace_module}
  use_single_view: false
  use_multi_view_condition: true
  n_views: null
  theta: null
  radius: null

  args:
    batch_size: 8